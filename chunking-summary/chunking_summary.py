import os
from pypdf import PdfReader
from openai import OpenAI
import tiktoken
# creating a pdf reader object 
max_summary_token_len = 200
client = OpenAI(
    api_key= os.environ.get("OPEN_AI_API_KEY"),
)

def extract_text_from_pdf(book_path):
    reader = PdfReader('../books_for_summary/charlie_and_the_chocolate_factory.pdf') 
    start_page = 3
    end_page = len(reader.pages) 
    extracted_text = ""
    for page_num in range(start_page, end_page):
        extracted_text += reader.pages[page_num].extract_text()
    return extracted_text

def text_to_chunks_based_on_token():
    # https://stackoverflow.com/questions/70060847/how-to-work-with-openai-maximum-context-length-is-2049-tokens - considering 4096 tokens
    # Max tokens = Input words sent to model + Output generated by model.
    # Keeping output as 200 words - so that will need appx 267 tokens. With all that calculation we will have word limit of about 2700 words for each chunk of data that can be sent to OpenAI API
    pass

def summarize_text(text):
    response = client.completions.create(
       model="gpt-3.5-turbo",
        prompt=f"Summarize the following text:\n\n{text}",
        max_tokens=max_summary_token_len,
        n=1,
        stop=None,
        temperature=0.7,
    )
    return response.choices[0].text.strip()

extracted_text = extract_text_from_pdf('../books_for_summary/charlie_and_the_chocolate_factory.pdf')
summarize_text(extracted_text)
